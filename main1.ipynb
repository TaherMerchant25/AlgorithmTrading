{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f7c3d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import os.path\n",
    "from binance.client import Client\n",
    "from ta.momentum import RSIIndicator\n",
    "from ta.trend import MACD, ADXIndicator\n",
    "from ta.volatility import AverageTrueRange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a50d26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ichimoku Cloud functions\n",
    "def calculate_tenkan_sen(high, low, period=9):\n",
    "    \"\"\"Calculate Tenkan-sen (Conversion Line)\"\"\"\n",
    "    highs = high.rolling(window=period).max()\n",
    "    lows = low.rolling(window=period).min()\n",
    "    return (highs + lows) / 2\n",
    "\n",
    "def calculate_kijun_sen(high, low, period=26):\n",
    "    \"\"\"Calculate Kijun-sen (Base Line)\"\"\"\n",
    "    highs = high.rolling(window=period).max()\n",
    "    lows = low.rolling(window=period).min()\n",
    "    return (highs + lows) / 2\n",
    "\n",
    "def ichimoku_cloud(high, low, close, tenkan_period=9, kijun_period=26):\n",
    "    \"\"\"Calculate Ichimoku Cloud components\"\"\"\n",
    "    tenkan_sen = calculate_tenkan_sen(high, low, tenkan_period)\n",
    "    kijun_sen = calculate_kijun_sen(high, low, kijun_period)\n",
    "    \n",
    "    # Calculate Senkou Span A (Leading Span A)\n",
    "    senkou_span_a = ((tenkan_sen + kijun_sen) / 2).shift(kijun_period)\n",
    "    \n",
    "    # Calculate Senkou Span B (Leading Span B)\n",
    "    senkou_span_b = ((high.rolling(window=52).max() + low.rolling(window=52).min()) / 2).shift(kijun_period)\n",
    "    \n",
    "    # Calculate Chikou Span (Lagging Span)\n",
    "    chikou_span = close.shift(-kijun_period)\n",
    "    \n",
    "    return tenkan_sen, kijun_sen, senkou_span_a, senkou_span_b, chikou_span\n",
    "\n",
    "def calculate_heikin_ashi(df):\n",
    "    \"\"\"\n",
    "    Calculate Heikin-Ashi candles from regular OHLC data\n",
    "    \"\"\"\n",
    "    ha_df = df.copy()\n",
    "    \n",
    "    # First create all necessary columns\n",
    "    ha_df['HA_Close'] = (df['open'] + df['high'] + df['low'] + df['close']) / 4\n",
    "    ha_df['HA_Open'] = df['open'].copy()  # Initialize with regular open values\n",
    "    \n",
    "    # For the first candle, HA_Open equals the regular open (already set above)\n",
    "    # Calculate HA_Open for the rest\n",
    "    for i in range(1, len(df)):\n",
    "        ha_df.iloc[i, ha_df.columns.get_loc('HA_Open')] = (ha_df['HA_Open'].iloc[i-1] + ha_df['HA_Close'].iloc[i-1]) / 2\n",
    "    \n",
    "    ha_df['HA_High'] = ha_df[['high', 'HA_Open', 'HA_Close']].max(axis=1)\n",
    "    ha_df['HA_Low'] = ha_df[['low', 'HA_Open', 'HA_Close']].min(axis=1)\n",
    "    \n",
    "    return ha_df\n",
    "\n",
    "def prepare_data(symbol=\"BTCUSDT\", interval=\"1h\", limit=500, use_csv=True, csv_path='1hr.csv'):\n",
    "    \"\"\"\n",
    "    Prepare complete dataset for the trading strategy by:\n",
    "    1. Loading data from CSV or fetching from Binance API\n",
    "    2. Calculating technical indicators\n",
    "    3. Creating Heikin-Ashi candles\n",
    "    4. Processing clustering data if available\n",
    "    \n",
    "    Parameters:\n",
    "    - symbol: Trading pair to analyze\n",
    "    - interval: Timeframe for the data\n",
    "    - limit: Number of candles to fetch\n",
    "    - use_csv: Whether to use CSV file or fetch from API\n",
    "    - csv_path: Path to the CSV file with data\n",
    "    \n",
    "    Returns:\n",
    "    - Complete DataFrame ready for the strategy\n",
    "    \"\"\"\n",
    "    if use_csv and os.path.exists(csv_path):\n",
    "        print(f\"Loading data from {csv_path}...\")\n",
    "        df = pd.read_csv(csv_path)\n",
    "        \n",
    "        # Check if all required columns are present\n",
    "        required_columns = ['timestamp', 'open', 'high', 'low', 'close']\n",
    "        missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "        \n",
    "        if missing_columns:\n",
    "            print(f\"Error: Missing required columns: {missing_columns}\")\n",
    "            print(\"Falling back to Binance API...\")\n",
    "            use_csv = False\n",
    "    elif use_csv:\n",
    "        print(f\"CSV file {csv_path} not found, falling back to Binance API...\")\n",
    "        use_csv = False\n",
    "    \n",
    "    if not use_csv:\n",
    "        # Fetch data from Binance API\n",
    "        print(f\"Fetching {symbol} data from Binance ({interval} interval)...\")\n",
    "        client = Client()\n",
    "        klines = client.get_klines(symbol=symbol, interval=interval, limit=limit)\n",
    "        \n",
    "        df = pd.DataFrame(klines, columns=[\n",
    "            'timestamp', 'open', 'high', 'low', 'close', 'volume',\n",
    "            'close_time', 'quote_asset_volume', 'number_of_trades',\n",
    "            'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignore'\n",
    "        ])\n",
    "        \n",
    "        # Convert types\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "        for col in ['open', 'high', 'low', 'close', 'volume']:\n",
    "            df[col] = df[col].astype(float)\n",
    "    \n",
    "    # Make sure timestamp is datetime\n",
    "    if 'timestamp' in df.columns and not pd.api.types.is_datetime64_any_dtype(df['timestamp']):\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    \n",
    "    # Calculate technical indicators\n",
    "    # RSI\n",
    "    if 'RSI' not in df.columns:\n",
    "        df['RSI'] = RSIIndicator(close=df['close'], window=14).rsi()\n",
    "    \n",
    "    # MACD\n",
    "    if 'MACD' not in df.columns:\n",
    "        macd = MACD(close=df['close'])\n",
    "        df['MACD'] = macd.macd()\n",
    "        df['MACD_Signal'] = macd.macd_signal()\n",
    "    \n",
    "    # EMA calculations\n",
    "    df['EMA_9'] = df['close'].ewm(span=9, adjust=False).mean()\n",
    "    df['EMA_14'] = df['close'].ewm(span=14, adjust=False).mean()\n",
    "    \n",
    "    # ATR calculation\n",
    "    atr_indicator = AverageTrueRange(high=df['high'], low=df['low'], close=df['close'], window=11)\n",
    "    df['ATR'] = atr_indicator.average_true_range()\n",
    "    \n",
    "    # ADX calculation for trend strength\n",
    "    adx_indicator = ADXIndicator(high=df['high'], low=df['low'], close=df['close'], window=14)\n",
    "    df['ADX'] = adx_indicator.adx()\n",
    "    \n",
    "    # Ichimoku Cloud components\n",
    "    tenkan_sen, kijun_sen, senkou_span_a, senkou_span_b, chikou_span = ichimoku_cloud(\n",
    "        df['high'], df['low'], df['close'], 15, 30\n",
    "    )\n",
    "    df['Tenkan_Sen'] = tenkan_sen\n",
    "    df['Kijun_Sen'] = kijun_sen\n",
    "    df['Senkou_Span_A'] = senkou_span_a\n",
    "    df['Senkou_Span_B'] = senkou_span_b\n",
    "    df['Chikou_Span'] = chikou_span\n",
    "    \n",
    "    # Calculate Heikin-Ashi candles\n",
    "    df = calculate_heikin_ashi(df)\n",
    "    \n",
    "    # Add other features from original code\n",
    "    df['HL_Volatility'] = df['high'] - df['low']\n",
    "    df['Body'] = df['close'] - df['open']\n",
    "    df['Volume_Change'] = df['volume'].pct_change().fillna(0)\n",
    "    df['Price_Change'] = df['close'].diff().fillna(0)\n",
    "    df['Pct_Change'] = df['close'].pct_change().fillna(0)\n",
    "    df['Upper_Shadow'] = df['high'] - df[['open', 'close']].max(axis=1)\n",
    "    df['Lower_Shadow'] = df[['open', 'close']].min(axis=1) - df['low']\n",
    "    df['SMA_14'] = df['close'].rolling(window=14).mean()\n",
    "    df['Momentum'] = df['close'] - df['close'].shift(14)\n",
    "    df['Rolling_Volatility_14'] = df['close'].pct_change().rolling(14).std()\n",
    "    \n",
    "    # Initialize Position and Signal columns for the strategy\n",
    "    df['Position'] = 0\n",
    "    df['Signal'] = 0\n",
    "    \n",
    "    # Reset index to make it easier to work with iloc in the strategy\n",
    "    if 'timestamp' in df.columns:\n",
    "        df = df.set_index('timestamp')\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9639bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_trade_strategy(df):\n",
    "    \"\"\"\n",
    "    Implement the original trading strategy but structured like in A.py\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame with price data and technical indicators\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with trading signals and positions\n",
    "    \"\"\"\n",
    "    # Make a copy of the dataframe\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Reset index for easier iteration\n",
    "    if df_copy.index.name == 'timestamp':\n",
    "        df_copy = df_copy.reset_index()\n",
    "    \n",
    "    stop_loss = 0\n",
    "    \n",
    "    for i in range(30, len(df_copy)-1):  # Skip first 30 rows for indicator calculation\n",
    "        # RSI-based signals from original strategy\n",
    "        if df_copy['RSI'].iloc[i] > 85 and df_copy['Kijun_Sen'].iloc[i] > df_copy['Tenkan_Sen'].iloc[i]:\n",
    "            # Consider cluster sentiment if available\n",
    "            proceed_with_signal = True\n",
    "            \n",
    "            if ('KMeans_Sentiment' in df_copy.columns and 'DTW_Sentiment' in df_copy.columns):\n",
    "                kmeans_sentiment = df_copy['KMeans_Sentiment'].iloc[i]\n",
    "                dtw_sentiment = df_copy['DTW_Sentiment'].iloc[i]\n",
    "                \n",
    "                # Cancel sell signal if both clustering methods indicate bullish sentiment\n",
    "                if kmeans_sentiment == 'Bullish' and dtw_sentiment == 'Bullish':\n",
    "                    proceed_with_signal = False\n",
    "            \n",
    "            if proceed_with_signal and df_copy['Position'].iloc[i] != -1:\n",
    "                df_copy.loc[i+1, 'Position'] = -1  # Sell/Short signal\n",
    "                df_copy.loc[i, 'Signal'] = -1 - df_copy.loc[i, 'Position']\n",
    "                stop_loss = df_copy['high'].iloc[i] + 2*df_copy['ATR'].iloc[i]\n",
    "                \n",
    "        elif df_copy['RSI'].iloc[i] < 30 and df_copy['Kijun_Sen'].iloc[i] < df_copy['Tenkan_Sen'].iloc[i]:\n",
    "            # Consider cluster sentiment if available\n",
    "            proceed_with_signal = True\n",
    "            \n",
    "            if ('KMeans_Sentiment' in df_copy.columns and 'DTW_Sentiment' in df_copy.columns):\n",
    "                kmeans_sentiment = df_copy['KMeans_Sentiment'].iloc[i]\n",
    "                dtw_sentiment = df_copy['DTW_Sentiment'].iloc[i]\n",
    "                \n",
    "                # Cancel buy signal if both clustering methods indicate bearish sentiment\n",
    "                if kmeans_sentiment == 'Bearish' and dtw_sentiment == 'Bearish':\n",
    "                    proceed_with_signal = False\n",
    "            \n",
    "            if proceed_with_signal and df_copy['Position'].iloc[i] != 1:\n",
    "                df_copy.loc[i+1, 'Position'] = 1  # Buy signal\n",
    "                df_copy.loc[i, 'Signal'] = 1 - df_copy.loc[i, 'Position']\n",
    "                stop_loss = df_copy['low'].iloc[i] - 2*df_copy['ATR'].iloc[i]\n",
    "        \n",
    "        # New condition: Exit positions when sentiment changes strongly against current position\n",
    "        elif ('KMeans_Sentiment' in df_copy.columns and 'DTW_Sentiment' in df_copy.columns):\n",
    "            kmeans_sentiment = df_copy['KMeans_Sentiment'].iloc[i]\n",
    "            dtw_sentiment = df_copy['DTW_Sentiment'].iloc[i]\n",
    "            \n",
    "            sentiment_score = 0\n",
    "            if kmeans_sentiment == 'Bullish':\n",
    "                sentiment_score += 1\n",
    "            elif kmeans_sentiment == 'Bearish':\n",
    "                sentiment_score -= 1\n",
    "                \n",
    "            if dtw_sentiment == 'Bullish':\n",
    "                sentiment_score += 1\n",
    "            elif dtw_sentiment == 'Bearish':\n",
    "                sentiment_score -= 1\n",
    "            \n",
    "            # Exit long if strong bearish sentiment\n",
    "            if df_copy['Position'].iloc[i] == 1 and sentiment_score < -1:\n",
    "                df_copy.loc[i+1, 'Position'] = 0\n",
    "                df_copy.loc[i, 'Signal'] = -1\n",
    "            \n",
    "            # Exit short if strong bullish sentiment\n",
    "            elif df_copy['Position'].iloc[i] == -1 and sentiment_score > 1:\n",
    "                df_copy.loc[i+1, 'Position'] = 0\n",
    "                df_copy.loc[i, 'Signal'] = 1\n",
    "        \n",
    "        else:\n",
    "            # Manage existing positions\n",
    "            if df_copy['Position'].iloc[i] == 1:  # Currently long\n",
    "                df_copy.loc[i+1, 'Position'] = 1\n",
    "                # Check stop loss\n",
    "                if df_copy['low'].iloc[i] < stop_loss:\n",
    "                    df_copy.loc[i+1, 'Position'] = 0\n",
    "                    df_copy.loc[i, 'Signal'] = -1\n",
    "                else:\n",
    "                    # Trail stop loss\n",
    "                    stop_loss = max(stop_loss, df_copy['low'].iloc[i] - 2*df_copy['ATR'].iloc[i])\n",
    "            \n",
    "            elif df_copy['Position'].iloc[i] == -1:  # Currently short\n",
    "                df_copy.loc[i+1, 'Position'] = -1\n",
    "                # Check stop loss\n",
    "                if df_copy['high'].iloc[i] > stop_loss:\n",
    "                    df_copy.loc[i+1, 'Position'] = 0\n",
    "                    df_copy.loc[i, 'Signal'] = 1\n",
    "                else:\n",
    "                    # Trail stop loss\n",
    "                    stop_loss = min(stop_loss, df_copy['high'].iloc[i] + 2*df_copy['ATR'].iloc[i])\n",
    "            \n",
    "            else:  # No position\n",
    "                df_copy.loc[i+1, 'Position'] = 0\n",
    "    \n",
    "    # Restore index if needed\n",
    "    if 'timestamp' in df_copy.columns:\n",
    "        df_copy = df_copy.set_index('timestamp')\n",
    "    \n",
    "    return df_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304cf962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_strategy_performance(df, initial_balance=10000):\n",
    "    \"\"\"\n",
    "    Calculate performance metrics for the trading strategy.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame with Position and close price columns\n",
    "    - initial_balance: Initial balance for the simulation\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary of performance metrics\n",
    "    \"\"\"\n",
    "    # Calculate strategy returns\n",
    "    df['Strategy_Returns'] = df['Position'].shift(1) * df['close'].pct_change()\n",
    "    df['Cumulative_Returns'] = (1 + df['Strategy_Returns'].fillna(0)).cumprod() - 1\n",
    "    \n",
    "    # Calculate Buy & Hold returns for comparison\n",
    "    df['BuyHold_Returns'] = df['close'].pct_change()\n",
    "    df['BuyHold_Cumulative'] = (1 + df['BuyHold_Returns'].fillna(0)).cumprod() - 1\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    total_return = df['Cumulative_Returns'].iloc[-1]\n",
    "    \n",
    "    # Calculate annualized metrics\n",
    "    trading_days = len(df)\n",
    "    annualized_return = ((1 + total_return) ** (365 / trading_days)) - 1 if trading_days > 0 else 0\n",
    "    \n",
    "    # Calculate volatility and Sharpe ratio\n",
    "    daily_returns = df['Strategy_Returns'].fillna(0)\n",
    "    volatility = daily_returns.std() * np.sqrt(365)  # Annualized\n",
    "    sharpe_ratio = annualized_return / volatility if volatility > 0 else 0\n",
    "    \n",
    "    # Maximum drawdown\n",
    "    cumulative_returns = df['Cumulative_Returns'].fillna(0)\n",
    "    peak = cumulative_returns.expanding().max()\n",
    "    drawdown = (cumulative_returns - peak) / (peak + 1)  # Add 1 to avoid division by zero\n",
    "    max_drawdown = drawdown.min()\n",
    "    \n",
    "    # Trade statistics\n",
    "    trades = df[df['Signal'] != 0]\n",
    "    total_trades = len(trades)\n",
    "    profitable_trades = len(df[df['Strategy_Returns'] > 0])\n",
    "    win_rate = (profitable_trades / total_trades) * 100 if total_trades > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'total_return': total_return * 100,  # Convert to percentage\n",
    "        'annualized_return': annualized_return * 100,\n",
    "        'volatility': volatility * 100,\n",
    "        'sharpe_ratio': sharpe_ratio,\n",
    "        'max_drawdown': max_drawdown * 100,\n",
    "        'win_rate': win_rate,\n",
    "        'total_trades': total_trades\n",
    "    }\n",
    "\n",
    "def print_performance_metrics(metrics):\n",
    "    \"\"\"Print formatted performance metrics\"\"\"\n",
    "    print(\"\\n===== STRATEGY PERFORMANCE =====\")\n",
    "    print(f\"Total Return: {metrics['total_return']:.2f}% \")\n",
    "    print(f\"Annualized Return: {metrics['annualized_return']:.2f}%\")\n",
    "    print(f\"Volatility: {metrics['volatility']:.2f}%\")\n",
    "    print(f\"Sharpe Ratio: {metrics['sharpe_ratio']:.2f}  \")\n",
    "    print(f\"Max Drawdown: -{metrics['max_drawdown']:.2f}%\")\n",
    "    print(f\"Win Rate: {metrics['win_rate']:.2f}%    \")\n",
    "    print(f\"Total Trades: {metrics['total_trades']}\")\n",
    "\n",
    "def plot_strategy_results(df, title=\"Strategy Performance\"):\n",
    "    \"\"\"\n",
    "    Plot the trading strategy results including:\n",
    "    - Price chart with buy/sell signals\n",
    "    - Equity curve\n",
    "    - RSI indicator\n",
    "    - Cluster sentiment if available\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame with strategy results\n",
    "    - title: Title for the plot\n",
    "    \"\"\"\n",
    "    # Create plot with subplots\n",
    "    fig, axs = plt.subplots(3, 1, figsize=(16, 16), gridspec_kw={'height_ratios': [2, 1, 1]})\n",
    "    \n",
    "    # Plot 1: Price chart with buy/sell markers\n",
    "    axs[0].plot(df.index, df['close'], label='BTC Price', color='gray')\n",
    "    \n",
    "    # Add Buy markers (signals of 1)\n",
    "    buy_signals = df[df['Signal'] == 1]\n",
    "    if not buy_signals.empty:\n",
    "        axs[0].scatter(buy_signals.index, buy_signals['close'], marker='^', color='green', s=100, label='Buy')\n",
    "    \n",
    "    # Add Sell markers (signals of -1)\n",
    "    sell_signals = df[df['Signal'] == -1]\n",
    "    if not sell_signals.empty:\n",
    "        axs[0].scatter(sell_signals.index, sell_signals['close'], marker='v', color='red', s=100, label='Sell')\n",
    "    \n",
    "    axs[0].set_title(f'{title} - Price with Buy/Sell Signals')\n",
    "    axs[0].set_ylabel('Price (USD)')\n",
    "    axs[0].legend()\n",
    "    axs[0].grid(True)\n",
    "    \n",
    "    # Plot 2: Strategy returns vs Buy & Hold\n",
    "    axs[1].plot(df.index, df['Cumulative_Returns'] * 100, label='Strategy Returns', color='blue')\n",
    "    axs[1].plot(df.index, df['BuyHold_Cumulative'] * 100, label='Buy & Hold', color='gray', alpha=0.5)\n",
    "    axs[1].set_title('Cumulative Returns')\n",
    "    axs[1].set_ylabel('Returns (%)')\n",
    "    axs[1].legend()\n",
    "    axs[1].grid(True)\n",
    "    \n",
    "    # Plot 3: RSI with overbought/oversold lines and cluster sentiment if available\n",
    "    if 'RSI' in df.columns:\n",
    "        axs[2].plot(df.index, df['RSI'], label='RSI', color='purple')\n",
    "        axs[2].axhline(y=85, color='r', linestyle='--', label='Overbought (85)')\n",
    "        axs[2].axhline(y=30, color='g', linestyle='--', label='Oversold (30)')\n",
    "        axs[2].set_title('RSI Indicator')\n",
    "        axs[2].set_ylabel('RSI Value')\n",
    "        axs[2].legend(loc='upper left')\n",
    "        axs[2].grid(True)\n",
    "        \n",
    "        # Plot cluster sentiment if available on secondary y-axis\n",
    "        if 'KMeans_Sentiment' in df.columns and 'DTW_Sentiment' in df.columns:\n",
    "            ax2 = axs[2].twinx()\n",
    "            \n",
    "            # Convert sentiment to numeric for plotting\n",
    "            sentiment_map = {'Bearish': -1, 'Sideways': 0, 'Bullish': 1}\n",
    "            kmeans_sentiment_numeric = df['KMeans_Sentiment'].map(sentiment_map)\n",
    "            dtw_sentiment_numeric = df['DTW_Sentiment'].map(sentiment_map)\n",
    "            \n",
    "            ax2.plot(df.index, kmeans_sentiment_numeric, label='KMeans Sentiment', color='blue', alpha=0.5)\n",
    "            ax2.plot(df.index, dtw_sentiment_numeric, label='DTW Sentiment', color='green', alpha=0.5)\n",
    "            ax2.set_ylabel('Sentiment')\n",
    "            ax2.set_yticks([-1, 0, 1])\n",
    "            ax2.set_yticklabels(['Bearish', 'Sideways', 'Bullish'])\n",
    "            ax2.legend(loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('strategy_results.png')\n",
    "    plt.show()\n",
    "\n",
    "def run_strategy_pipeline(use_csv=True, csv_path='btc_hourly_clustered_extended1.csv', \n",
    "                        symbol=\"BTCUSDT\", interval=\"1h\", limit=500, initial_balance=10000):\n",
    "    \"\"\"\n",
    "    Complete end-to-end pipeline to fetch data, run the strategy, analyze performance,\n",
    "    and visualize results.\n",
    "    \"\"\"\n",
    "    # Step 1: Prepare data \n",
    "    df = prepare_data(symbol=symbol, interval=interval, limit=limit, \n",
    "                      use_csv=use_csv, csv_path=csv_path)\n",
    "    \n",
    "    # Step 2: Execute trading strategy\n",
    "    df = execute_trade_strategy(df)\n",
    "    \n",
    "    # Step 3: Analyze performance\n",
    "    metrics = analyze_strategy_performance(df, initial_balance)\n",
    "    \n",
    "    # Step 4: Print performance metrics\n",
    "    print_performance_metrics(metrics)\n",
    "    \n",
    "    # Step 5: Visualize results\n",
    "    plot_strategy_results(df, title=\"RSI-Ichimoku Strategy with Clustering\")\n",
    "    \n",
    "    # Step 6: Save results\n",
    "    df.to_csv(\"strategy_results_with_clusters.csv\")\n",
    "    \n",
    "    return df, metrics\n",
    "\n",
    "# Enable direct execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the complete pipeline\n",
    "    df, metrics = run_strategy_pipeline(\n",
    "        use_csv=True,                         # Set to False to use Binance API directly\n",
    "        csv_path='btc_hourly_clustered_extended1.csv',  # Path to clustering data\n",
    "        symbol=\"BTCUSDT\",                     # Trading pair\n",
    "        interval=Client.KLINE_INTERVAL_1HOUR, # Time interval\n",
    "        limit=500,                            # Number of records\n",
    "        initial_balance=10000                 # Initial balance\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
